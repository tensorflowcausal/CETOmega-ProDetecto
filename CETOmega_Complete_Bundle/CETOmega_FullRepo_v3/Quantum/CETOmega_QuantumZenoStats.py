#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# CETOmega_QuantumZenoStats.py - Model comparison for Quantum Zeno datasets
# Author: Dr. Christian Balfagon (UBA) - helper script generated by assistant
# License: MIT
#
# Compares:
#   H0: Markov (constant Gamma_Z)
#   H1: Power-law Gamma_Z ~ Δt^{-alpha}
#   H2: CETOmega Gamma_Z(Δt)=F(1/Δt)*Gamma0 with F from kernel JSON (fixed spectrum)
#
# Input CSV: experiment_id,delta_t_ns,P_nojump,sigma_P
# Output: JSON report with loglike, AIC, BIC, Bayes factors, (optional) bootstrap winner counts.
#
import json, csv, argparse, math, sys, random
from typing import List, Dict, Any, Tuple, Optional
import numpy as np

def read_zeno_csv(path: str) -> List[Dict[str, Any]]:
    rows = []
    with open(path, 'r', encoding='utf-8') as f:
        for line in f:
            if not line.strip() or line.strip().startswith('#'):
                continue
            parts = [x.strip() for x in line.strip().split(',')]
            if len(parts) < 4:
                continue
            exp, dt, P, sP = parts[:4]
            try:
                rows.append({
                    'experiment_id': exp,
                    'delta_t_ns': float(dt),
                    'P_nojump': float(P),
                    'sigma_P': float(sP)
                })
            except Exception:
                continue
    return rows

def F_from_kernel(kernel_json: str, freqs: np.ndarray) -> np.ndarray:
    # F(omega) = omega^2 * sum c_j/(omega^2 + m_j^2) normalized by sum c_j
    try:
        with open(kernel_json, 'r', encoding='utf-8') as f:
            data = json.load(f)
        poles = data.get('poles', [])
        csum = sum([float(p.get('c', p.get('cj', p.get('c_j', 0.0)))) for p in poles])
        if csum <= 0 or len(poles)==0:
            return np.ones_like(freqs)
        num = np.zeros_like(freqs, dtype=float)
        for p in poles:
            c = float(p.get('c', p.get('cj', p.get('c_j', 0.0))))
            m = float(p.get('m', p.get('mj', p.get('m_j', 0.0))))
            num += c * (freqs*freqs)/(freqs*freqs + m*m)
        F = num / csum
        # clamp numerical noise
        F = np.clip(F, 0.0, 1.0)
        return F
    except Exception:
        return np.ones_like(freqs)

def loglike_gauss(y: np.ndarray, yhat: np.ndarray, s: np.ndarray) -> float:
    mask = (s > 0) & np.isfinite(y) & np.isfinite(yhat)
    y, yhat, s = y[mask], yhat[mask], s[mask]
    if y.size == 0:
        return float('-inf')
    resid = (y - yhat)/s
    return float(np.sum(-0.5*(resid**2 + np.log(2*np.pi*s*s))))

def fit_markov(dt: np.ndarray, P: np.ndarray, sP: np.ndarray) -> Tuple[np.ndarray, Dict[str,float], int]:
    # Markov: P_nojump = exp(-Gamma0 * T), approximate per-interrogation with T=Δt (scaling factor absorbed)
    # We fit Gamma0 by weighted least squares on log(P) ~ -Gamma0 * Δt_eff
    eps = 1e-12
    w = 1.0/np.maximum(eps, sP)**2
    y = -np.log(np.clip(P, eps, 1.0-eps))
    X = dt.reshape(-1,1)
    # solve Gamma0 = argmin ||sqrt(w)*(y - X*Gamma0)||^2
    Gamma0 = float(np.sum(w*X[:,0]*y)/np.sum(w*X[:,0]*X[:,0]))
    P_hat = np.exp(-Gamma0*dt)
    return P_hat, {'Gamma0': Gamma0}, 1  # k=1

def fit_powerlaw(dt: np.ndarray, P: np.ndarray, sP: np.ndarray) -> Tuple[np.ndarray, Dict[str,float], int]:
    # Power-law for rate: Gamma(dt) = A * dt^{-alpha} => P = exp(-Gamma(dt)*dt) = exp(-A * dt^{1-alpha})
    # Fit A and alpha by simple grid or local search; here coarse grid then refine
    A_grid = np.logspace(-6, 1, 50)
    alpha_grid = np.linspace(-1.0, 2.0, 60)
    best = None
    for A in A_grid:
        for alpha in alpha_grid:
            yhat = np.exp(-A * (dt**(1.0 - alpha)))
            ll = loglike_gauss(P, yhat, sP)
            if (best is None) or (ll > best[0]):
                best = (ll, A, alpha, yhat)
    ll, A, alpha, yhat = best
    return yhat, {'A': A, 'alpha': alpha}, 2  # k=2

def fit_cet(dt: np.ndarray, P: np.ndarray, sP: np.ndarray, kernel_json: str) -> Tuple[np.ndarray, Dict[str,float], int]:
    # CET: Gamma_Z(dt) = Gamma0 * F(1/dt_eff). We set dt in seconds using ns->s.
    # Use F from kernel JSON, fit only Gamma0 (one scalar), spectrum fixed.
    dt_s = dt * 1e-9
    omega = 1.0/np.maximum(1e-30, dt_s)
    F = F_from_kernel(kernel_json, omega)
    # P = exp(-Gamma0 * F * dt_s_eff) -> use dt_s as effective time
    X = (F * dt_s)
    eps = 1e-12
    w = 1.0/np.maximum(eps, sP)**2
    y = -np.log(np.clip(P, eps, 1.0-eps))
    Gamma0 = float(np.sum(w*X*y)/np.sum(w*X*X))
    yhat = np.exp(-Gamma0 * X)
    return yhat, {'Gamma0': Gamma0}, 1  # k=1

def model_compare(rows: List[Dict[str,Any]], kernel_json: str) -> Dict[str, Any]:
    dt = np.array([r['delta_t_ns'] for r in rows], dtype=float)
    P  = np.array([r['P_nojump'] for r in rows], dtype=float)
    sP = np.array([r['sigma_P'] for r in rows], dtype=float)
    n = len(rows)

    # Fit each model
    y_M, params_M, kM = fit_markov(dt, P, sP)
    y_PL, params_PL, kPL = fit_powerlaw(dt, P, sP)
    y_CET, params_CET, kCET = fit_cet(dt, P, sP, kernel_json)

    # Log-likelihoods
    ll = {
        'Markov': loglike_gauss(P, y_M, sP),
        'PowerLaw': loglike_gauss(P, y_PL, sP),
        'CETOmega': loglike_gauss(P, y_CET, sP)
    }
    k = {'Markov': kM, 'PowerLaw': kPL, 'CETOmega': kCET}
    aic = {m: -2*ll[m] + 2*k[m] for m in ll}
    bic = {m: -2*ll[m] + k[m]*math.log(max(1,n)) for m in ll}

    # Bayes factors via BIC approx
    def BF(ref: str, alt: str) -> float:
        d = bic[alt] - bic[ref]
        lnB = -0.5*d
        try:
            return float(math.exp(lnB))
        except OverflowError:
            return float('inf') if lnB>0 else 0.0
    bayes = {
        'CETOmega_vs_Markov': BF('Markov','CETOmega'),
        'CETOmega_vs_PowerLaw': BF('PowerLaw','CETOmega'),
        'PowerLaw_vs_Markov': BF('Markov','PowerLaw')
    }

    return {
        'n_points': n,
        'params': {'Markov': params_M, 'PowerLaw': params_PL, 'CETOmega': params_CET},
        'loglike': ll,
        'AIC': aic,
        'BIC': bic,
        'BayesFactor': bayes
    }

def bootstrap(rows: List[Dict[str,Any]], kernel_json: str, B: int=500, seed: int=42) -> Dict[str, Any]:
    rng = random.Random(seed)
    models = ['Markov','PowerLaw','CETOmega']
    counts = {m:0 for m in models}
    for _ in range(B):
        sample = [rng.choice(rows) for _ in rows]
        res = model_compare(sample, kernel_json)
        winner = min(res['BIC'].items(), key=lambda kv: kv[1])[0]
        counts[winner] += 1
    return {'bootstrap_winner_counts': counts, 'B': B}

def main():
    ap = argparse.ArgumentParser(description='CETOmega Quantum Zeno model comparison (BIC/AIC/Bayes + bootstrap)')
    ap.add_argument('--data', required=True, help='CSV: experiment_id,delta_t_ns,P_nojump,sigma_P')
    ap.add_argument('--cet-json', required=True, help='Kernel JSON with poles {c,m}')
    ap.add_argument('--out', required=True, help='Output JSON report')
    ap.add_argument('--boots', type=int, default=0, help='Bootstrap repetitions (0 disables)')
    ap.add_argument('--seed', type=int, default=42, help='Bootstrap RNG seed')
    args = ap.parse_args()

    rows = read_zeno_csv(args.data)
    if not rows:
        raise SystemExit('No valid rows in data.')

    report = {'input': {'data': args.data, 'cet_json': args.cet_json}}
    res = model_compare(rows, args.cet_json)
    report.update(res)

    if args.boots and args.boots>0:
        boot = bootstrap(rows, args.cet_json, B=args.boots, seed=args.seed)
        report.update(boot)

    with open(args.out, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(json.dumps({'status':'ok','out': args.out}, indent=2))

if __name__ == '__main__':
    main()
